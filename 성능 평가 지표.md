# 1. Precision / Recall
#### 참고 사이트 : https://better-today.tistory.com/3

#### 분류기 (Classifier) 의 성능을 평가하는 Metric에는 Precision/Recall 이 있다.

* Precision
    * `Precision = TP/(TP+FP)` or `TP/(분류기가 P 로 예측한 것)`
    * Precision 은 분류기가 `P로 예측한 sample 중`에서 맞게 예측한 것의 비율 을 의미한다. == 인식기 (object-detector) 가 검출한 정보들 중에서 Ground-Truth 와 일치하는 비율을 의미한다.
    * 검출된 정보(TP+FP) 중에서 적절한 것들(TP) 의 비율을 Precision 이라고 한다.
    * 영어 위키 : Precision is the probability that a retrieved(검출된) one is relevant(적절한).

* Recall 
    * `Recall = TP/(TP+FN)` or `TP/(Ground Truth P 의 숫자)`
    * 전체 정보(TP+FN)중에서 검출된 것(TP)의 비율을 Recall 이라고 한다.
    * 즉, Recall 은 `Ground Truth 의 총 positive sample 중`에서 `positive로 맞게 예측한 것`의 비율 을 의미한다.
    * 영어 위키 : Recall is the probability of the complete retrival(검출된).
<br/>
<br/>

# 2. mAP(mean Aaverage Precision)의 개념
#### 참고 사이트 : https://better-today.tistory.com/3

#### Computer Vision 쪽에 Object Detection 알고리즘 논문을 보면 성능평가지표로 mAP (mean Average Precision)이라는 것을 이용한다.

* `AP(Average Precision`란? : Recall value [0.0, 0.1, …, 1.0] 값들에 대응하는 Precision 값들의 Average 이다.

* mAP가 무엇인가?
    * 1개의 object당 1개의 AP 값을 구하고, 여러 object-detector 에 대해서 mean 값을 구한 것이 mAP 이다.
    * 즉, mAP란 mutiple object detection 알고리즘에 대한 성능을 1개의 scalar value로 표현한 것이다.

* 장/단점
    * 장점 1: 인식 threshold 에 의존성없이 성능평가가 가능하다.
    * 장점 2: mAP 평가를 통해 최적 threshold 를 정할 수 도 있다.
    * 단점 : 굉장히 느리다. 아무래도 모든 Test Image 에서 Threshold 0 이상의 box 를 추출하고 정렬하는 과정을 거쳐야 하기 때문이다.

* 성능 평가 지표 Python code(파이썬 코드)
    * 직접 구하는 방식
    ```
    # MAE
    def MAE(y_true, y_pred): 
        return np.mean(np.abs((y_true - y_pred)))

    print("MAE == ", MAE(y_true, y_pred))

    # MAPE
    def MAPE(y_true, y_pred): 
        return np.mean(np.abs((y_true - y_pred) / y_true))

    print("MAPE == ", MAPE(y_true, y_pred))

    # MSE
    def MSE(y_true, y_pred):
        return np.mean(np.square((y_true - y_pred)))

    print("MSE == ", MSE(y_true, y_pred))

    # RMSE
    print("RMSE == ", np.sqrt(MSE(y_true, y_pred)))

    ```
    * sklearn.metrics 사용하는 방식
    ```
    # MAE
    from sklearn.metrics import mean_absolute_error
    mean_absolute_error(y_true, y_pred)

    # MSE
    from sklearn.metrics import mean_squared_error
    mean_squared_error(y_true, y_pred)

    # RMSE
    np.sqrt(MSE(y_true, y_pred))
    ```